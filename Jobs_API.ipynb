{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a66c1692-9c84-41ec-a135-b417ef41344d",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2023-01-01\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e786144-f1e4-45ee-b287-f2f4b87300d3",
   "metadata": {},
   "source": [
    "# **JOBS API Implementation Using FLASK**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae78227-6f87-4090-80ab-49edba9c3003",
   "metadata": {},
   "source": [
    "Estimated time needed: **45 to 60** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817156a7-4bab-46b8-9a67-55f3b0564c01",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "You will be executing this code  so that the client application **Collecting Jobs API**  will be accessing this code executing on the server \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ac527ce-f921-44e2-b729-28ed03634a8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install flask\n",
    "#!pip install regex\n",
    "#!pip install re\n",
    "# %reset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5bba17-58e7-49a4-8040-0831e93466f5",
   "metadata": {},
   "source": [
    "## Dataset Used in this Assignment\n",
    "\n",
    "The dataset used in this lab comes from the following source: https://www.kaggle.com/promptcloud/jobs-on-naukricom under the under a **Public Domain license**.\n",
    "\n",
    "> Note: We are using a modified subset of that dataset for the lab, so to follow the lab instructions successfully please use the dataset provided with the lab, rather than the dataset from the original source.\n",
    "\n",
    "The original dataset is a csv. We have converted the csv to json as per the requirement of the lab.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2eed468-b4cd-481a-a18e-1851e2fc7a4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip install wget\n",
    "#%wget  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/module%201/Accessing%20Data%20Using%20APIs/jobs.json\n",
    "#%reset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2d6edde-4e06-4a70-a1e7-cd33d09e2c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.6\n"
     ]
    }
   ],
   "source": [
    "import flask\n",
    "from flask import request, jsonify\n",
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "def prnow():\n",
    "    print(datetime.datetime.now())\n",
    "#!pip install regex\n",
    "import re\n",
    "import regex\n",
    "!python --version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21697c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done defs  2024-10-08 14:16:14.315089\n"
     ]
    }
   ],
   "source": [
    "app = flask.Flask(__name__)\n",
    "\n",
    "def get_data(key,value,current):\n",
    "    print('get_data()')\n",
    "    results = list()\n",
    "    pattern_dict = {\n",
    "        'C'      : '(C)',\n",
    "        'C++'    : '(C\\\\+\\\\+)',\n",
    "        'Java'   :'(Java)',\n",
    "        'C#'     : '(C\\\\#)',\n",
    "        'Python' :'(Python)',\n",
    "        'Scala' : '(Scala)',\n",
    "        'Oracle' : '(Oracle)',\n",
    "        'SQL Server': '(SQL Server)',\n",
    "        'MySQL Server' :'(MySQL Server)',\n",
    "        'PostgreSQL':'(PostgreSQL)',\n",
    "        'MongoDB'    : '(MongoDB)',\n",
    "        'JavaScript'    : '(JavaScript)',\n",
    "        'Los Angeles' :'(Los Angeles)',\n",
    "        'New York':'(New York)',\n",
    "        'San Francisco':'(San Francisco)',\n",
    "        'Washington DC':'(Washington DC)',\n",
    "        'Seattle':'(Seattle)',\n",
    "        'Austin':'(Austin)',\n",
    "        'Detroit':'(Detroit)',\n",
    "        'Chicago':'(Chicago)',\n",
    "        'technology':'(technology)'\n",
    "        }\n",
    "    for rec in current:\n",
    "        print(rec[key])\n",
    "        print(type(rec[key]))\n",
    "        print(rec[key].find(value))\n",
    "        #if rec[key].find(value) != -1:\n",
    "        import re\n",
    "        #reex_str = \"\"\"(C)|(C\\+\\+)|(JavaScript)|(Java)|(C\\#)|(Python)|(Scala)|(Oracle)|(SQL Server)|(MySQL Server)|(PostgreSQL)|(MongoDB)\"\"\"\n",
    "        if re.search(pattern_dict[value],rec[key]) != None:\n",
    "            results.append(rec)\n",
    "    return results\n",
    "\n",
    "@app.route('/', methods=['GET'])\n",
    "def home():\n",
    "    return '''<h1>Welcome to flask JOB search API</p>'''\n",
    "\n",
    "@app.route('/data/all', methods=['GET'])\n",
    "def api_all():\n",
    "    print('api_all()')\n",
    "    return jsonify(data)\n",
    "\n",
    "@app.route('/data', methods=['GET'])\n",
    "def api_id():\n",
    "    # Check if keys such as Job Title,KeySkills, Role Category and others  are provided as part of the URL.\n",
    "    #  Assign the keys to the corresponding variables..\n",
    "    # If no key is provided, display an error in the browser.\n",
    "    print('app route data api_id()')\n",
    "    res = None\n",
    "    for req in request.args:\n",
    "        if req == 'Job Title':\n",
    "            key = 'Job Title'\n",
    "        elif req == 'Job Experience Required' :\n",
    "            key='Job Experience Required'\n",
    "        elif req == 'Key Skills' :\n",
    "            key='Key Skills'\n",
    "        elif req == 'Role Category' :\n",
    "            key='Role Category'\n",
    "        elif req == 'Location' :\n",
    "            key='Location'\n",
    "        elif req == 'Functional Area' :\n",
    "            key='Functional Area'\n",
    "        elif req == 'Industry' :\n",
    "            key='Industry'\n",
    "        elif req == 'Role' :\n",
    "            key='Role'\n",
    "        elif req=='Id':\n",
    "             key='Id'\n",
    "        elif req=='Location':\n",
    "             key='Location'     \n",
    "        else:\n",
    "            #pass\n",
    "            print('bad key in api_id() =', req)\n",
    "    \n",
    "        value = request.args[key]\n",
    "        if (res==None):\n",
    "            print('res is None from api_id(), get_data')\n",
    "            res = get_data(key,value,data)\n",
    "        else:\n",
    "            print('res is not None from api_id()')\n",
    "            res = get_data(key,value,res)\n",
    "\n",
    "    # Use the jsonify function from Flask to convert our list of\n",
    "    # Python dictionaries to the JSON format.\n",
    "    return jsonify(res)   # note, not json, but response object, supposedly\n",
    "print('done defs ', datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7e5d37f-23a8-4704-8011-a3d329246cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is a slow kludgy way to do it.  Someday change\n",
    "# it into a buffer of characters and write buffer to file\n",
    "# when you get matching { \" \" : \" \" } - if single list, only look at 1st and last chars\n",
    "# can use pop() on list or dict.  Could have { \"key\" : {subkey:subval,...\n",
    "# so when get closing char, pop out until matching char, else push on stack\n",
    "import regex\n",
    "replist = [\n",
    "        {r'\\\\r' : '' }, # remove carriage return left by DOS on MS Windows\n",
    "        {r',[\\\\t \\n]*\\]' : r'' },  # get rid of comma before ] end of list, regardless of newlines\n",
    "        {r',[\\\\t \\n]*\\}' : r'}' },  # get rid of comma before } end of {key:value}, regardless of newlines\n",
    "        {r'[\\\\t \\n]*\\]$' : r'' },  # for last bracket, move it up to previous line\n",
    "        # note that  [,  and  {,  could be valid syntax for empty first param BUT does it insert {{ ?\n",
    "        # for function calls or array indices\n",
    "        # but for json file, do fix\n",
    "        {r'\\[,' : '[' },\n",
    "        {r'\\{,' : '{' },\n",
    "        #{r'[\\\\t ]*\\[[\\\\t ]*\\n+'  : r'[' },  # forward to keep open bracket [ with text\n",
    "        {r'[\\\\t ]*\\{[\\\\t ]*\\n+'  : r'\\{' },  # debug1 forward to keep open brace { with text\n",
    "        {r'\\n+[\\\\t ]*\\}' : r'}' },  # back to keep closing brace with text\n",
    "        # what I would like to do is search for more than usual quotes and for that line sub all \" to '\n",
    "        # so then last 4 replacements will fix that. But also, what if uneven number like\n",
    "        # \"text1\" : \"text2 \"Michelen's Guide\" \" },  or \"text2 'comment for \"some lang\" \"\n",
    "        {r'\\\"' : \"\\'\" },  # change all double quotes to singles and then next subs will fix\n",
    "        {r'\\'[\\\\t ]*:' : r'\\\"\\:' },  # change single quote to double before :\n",
    "        {r':[\\\\t ]*\\'' : r'\\:\\\"' },  # change single quote after :\n",
    "        # below, what if we have {\"Jane's book\"    it's ok because only white space\n",
    "        {r'\\n+[\\\\t ]*\\{[\\\\t ]*\\'' : r'\\n {\"' },  #  debug quoteafterOpenCurlyl1'  change quote after newline and open line\n",
    "        {r'\\n+[\\\\t ]*\\'' : r'\\n \"' }, # single quote at beginning of line\n",
    "        {r'\\'[\\\\t ]*\\}' : r'\"}' },  # change single quote before } WORKS but did del t, now ok\n",
    "        {r'\\'[\\\\t ]*,' : r'\",' },  # change single quote comma newline WORKS but did del t, now ok\n",
    "        {r'[\\\\t ]*\\[[\\\\t ]*\\{[\\\\t ]*\\'' : r'{\"' },  ## another kludge - for 1st line\n",
    "        {r'\\\\' : r'' }, # get rid of remaining backslashes\n",
    "        {r'\\n[^\\[]' : r'\\n    ' }]  # add indent to all but close bracket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c60a4879-fe4f-4cb3-9023-179369bbde7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defined cleanjsonfile()\n",
      "2024-10-08 14:16:16.496903\n"
     ]
    }
   ],
   "source": [
    "# CURRENT  VERSION\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "import regex\n",
    "import re\n",
    "import os\n",
    "def one_dict(list_dict):  # from the IBM Data Analyst class on Coursera\n",
    "    keys=list_dict[0].keys()  # dict[0] are y columns, not x rows\n",
    "    out_dict={key:[] for key in keys}\n",
    "    for d in list_dict:\n",
    "        for key, value in d.items():\n",
    "            out_dict[key].append(value)\n",
    "    return out_dict\n",
    "dicjob = {}\n",
    "\n",
    "def cleanjsonfile():\n",
    "    import regex\n",
    "    print('function cleanjsonfile() entered ', datetime.datetime.now())\n",
    "    print('cwd is ', os.getcwd())\n",
    "\n",
    "    #myfile = 'jobs.json'\n",
    "    myfile = 'short.json'\n",
    "    \n",
    "    pathfn=os.path.join(os.getcwd(), myfile)\n",
    "    print('pathfn is ', pathfn)\n",
    "    #print('entering open read()')\n",
    "    with open(pathfn, mode='r', encoding='utf-8') as f:\n",
    "        longstring = f.read()\n",
    "        if not longstring:\n",
    "            print('f.read failed')\n",
    "    print('type of longstring is ', type(longstring))\n",
    "    print('len of longstring is ', len(longstring))\n",
    "    \n",
    "    #print('after read longstring = ', longstring)\n",
    "    # there are special characters and stuff in the file\n",
    "    # and jsonify does not seem to work, so clean it up and write to a new file\n",
    "    # below, white space or a newline is designated [\\t \\r] and * means any number of them\n",
    "    # could also remove formfeed \\f and backspace \\b\n",
    "    # some assumptions: 1. the target string is a list using outer [] of dictionaries using inner {}\n",
    "    #                   2. multi values use | not nested lists or key:value pairs, but i think nested stuff will be undisturbed\n",
    "    #                   3. when  ,]  or  ,}  or {,  assume the comma is in error and remove it, but leave [, in case of filtering\n",
    "    #                   4.  [  ]  {  } alone on a line are undesirable and json decode may not like them, so move forward or back\n",
    "    #                   5.  ,[  ,{  alone on a line are undesirable, and json might not accept them\n",
    "    #     \\s  isn't working, so use [\\t \\r] and sometimes [\\t \\r\\n \n",
    "    #print('len of longstring before editing = ', len(longstring))\n",
    "    #print('longstring is ', longstring)\n",
    "    # delete whole line, don't leave white space or excess newline\n",
    "    longstring1 = re.sub(r'\\n[\\\\\\\\t \\r\\n]*\\n' , r'\\n' , longstring)  # get rid of lines with white space\n",
    "    longstring = (\"\\n\".join(item for item in longstring1.split('\\n') if item))  # get rid of excess blank lines, stackoverflow\n",
    "    #print('longstring after split and join ', longstring)\n",
    "    replacements = {}\n",
    "    replacements = {k:v for e in replist for(k,v) in e.items()}  # turn list into dictionary\n",
    "    # a safe way to do 1 regex at a time use a for loop\n",
    "    cnt = 0\n",
    "    print('Beginning replacements, entering for loop')\n",
    "    for nonjson, fixjson in replacements.items():\n",
    "        cnt = cnt + 1\n",
    "        #print('doing sub ', cnt)\n",
    "        ##print('longstring slice ', longstring[longstring.find('Id'):longstring.find('}')+5] )\n",
    "        # may need to pause between substitutions to allow time for each update sequentially\n",
    "        # time.sleep(0.1) # Seconds\n",
    "        longstring = re.sub(nonjson, fixjson, longstring)\n",
    "    print('\\ntype of longstring is after for replacements ', type(longstring))\n",
    "    print('len of longstring is after for replacements = ', len(longstring))\n",
    "    #print('longstring after for replacements is ', longstring)\n",
    "    longstring = re.sub( r',\\n' , \",\" , longstring)  # remove newlines within {  } pairs\n",
    "    # restore newlines between dictionaries, kludey, i know\n",
    "    longstring = re.sub( r'},' , \"},\\n\" , longstring)  # restore newlines after {  } pairs\n",
    "    print('\\ntype of longstring is after newline fix ', type(longstring))\n",
    "    print('len of longstring is after newline fix = ', len(longstring))\n",
    "    #print('longstring after newline fix is ', longstring)\n",
    "    # fix 1st key has 'Id\"\n",
    "    longstring = re.sub(r\"'Id\", '\"Id', longstring, count=1)\n",
    "    # The longstring just has values. Need to prepend overall key \n",
    "    # print('\\n', type(longstring), 'longstring=', longstring)\n",
    "    # convert to list\n",
    "    lstjob = longstring.split('\\n')  # inserts commas in single quotes\n",
    "    # print('\\nlstjob is ', type(lstjob), lstjob)\n",
    "    dicjob = {}\n",
    "\n",
    "    dicjob = {i: value for i, value in enumerate(lstjob)}   \n",
    "    #print('\\n777dicjob is ', type(dicjob), dicjob)\n",
    " \n",
    "    myfile = 'newjobs.json'\n",
    "    pathfn=os.path.join(os.getcwd(), myfile)\n",
    "    with open(pathfn, mode='w+', encoding='utf-8') as f:\n",
    "        #### MY ERROR  nbrchars = f.write(longstring), but json.dump gives backslashes\n",
    "        #### that is CORRECT; it means the file is encoded for json\n",
    "        #f.write(longstring)\n",
    "        json.dump(dicjob, f)\n",
    "        print('WROTE the newjobs.json file via JSON.DUMP', datetime.datetime.now())\n",
    "print('defined cleanjsonfile()')\n",
    "prnow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c793d673-5b69-40ce-a505-95208b6ea715",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WAIT  until newjobs.json is written  2024-10-08 14:16:18.993791\n",
      "function cleanjsonfile() entered  2024-10-08 14:16:18.994791\n",
      "cwd is  C:\\Users\\krista\\fromExternal\\BackUps\\Classes\\IBM_Data_Analyst_Coursera\\CapstoneProject\n",
      "pathfn is  C:\\Users\\krista\\fromExternal\\BackUps\\Classes\\IBM_Data_Analyst_Coursera\\CapstoneProject\\short.json\n",
      "type of longstring is  <class 'str'>\n",
      "len of longstring is  3064\n",
      "Beginning replacements, entering for loop\n",
      "\n",
      "type of longstring is after for replacements  <class 'str'>\n",
      "len of longstring is after for replacements =  3063\n",
      "\n",
      "type of longstring is after newline fix  <class 'str'>\n",
      "len of longstring is after newline fix =  3007\n",
      "WROTE the newjobs.json file via JSON.DUMP 2024-10-08 14:16:19.002791\n"
     ]
    }
   ],
   "source": [
    "# %%timeit -n 1 -r 1   # later use n=250 and r=5 or something\n",
    "import datetime\n",
    "import regex\n",
    "print('WAIT  until newjobs.json is written ', datetime.datetime.now())\n",
    "cleanjsonfile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8117706b-d0fb-4333-a88f-c43ef2491c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json.load(f) complete  2024-10-08 14:16:30.929161\n"
     ]
    }
   ],
   "source": [
    "#print('Open newjobs.json and do data = json.load(f) ', datetime.datetime.now()) \n",
    "myfile = 'newjobs.json'\n",
    "pathfn=os.path.join(os.getcwd(), myfile)\n",
    "data = []\n",
    "with open(pathfn, mode='r', encoding='utf-8', errors=None) as f:\n",
    "    data = json.load(f)\n",
    "    #print('after json.load(f) type of data is ', type(data))\n",
    "print('json.load(f) complete ', datetime.datetime.now())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c40c2e5-9eab-43ec-86ed-2c52c6f91115",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [08/Oct/2024 14:23:31] \"GET /data/all HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api_all()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [08/Oct/2024 14:23:43] \"GET /data/all HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api_all()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [08/Oct/2024 16:00:06] \"GET /data/all HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api_all()\n"
     ]
    }
   ],
   "source": [
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416db877-1a38-4aae-a4e2-b139e4b44093",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TESTING CELL\") # testdata is tuple and testlist is list\n",
    "#https://www.google.com/search?q=python+type+dict+from+list+of+key-value+pairs+with+nested+lists&rlz=1C1UEAD_enUS1102US1102&oq=python+type+dict+from+list+of+key-value+pairs+with+nested+lists&gs_lcrp=EgZjaHJvbWUyBggAEEUYOdIBCTMzNTQxajBqN6gCCLACAQ&sourceid=chrome&ie=UTF-8\n",
    "testdata =  {\"Model\": \" 500\", \"Task\": \"71-00-00-200-802 \"},{ \"Model\": \" 900\",\"Task\": \" 71-00-00-200-802\" }\n",
    "testlist=[  { \"Model\": \" 500\", \"Task\": \"71-00-00-200-802 \" }, { \"Model\": \" 900\",\"Task\":\"71-00-00-200-802\" }]\n",
    "print('type of testdata is ', type(testdata)) # \n",
    "print('type of testlist is ', type(testlist)) # list\n",
    "\n",
    "def one_dict(list_dict):\n",
    "    keys=list_dict[0].keys()  # dict[0] are y columns, not x rows\n",
    "    out_dict={key:[] for key in keys}\n",
    "    for dict_ in list_dict:\n",
    "        for key, value in dict_.items():\n",
    "            out_dict[key].append(value)\n",
    "    return out_dict\n",
    "dictdata = one_dict(testlist)\n",
    "print('dictdata = \\n', dictdata)\n",
    "\n",
    "def create_dict(lst):\n",
    "    \"\"\"Creates a dictionary from a list of key-value pairs, handling nested lists.\"\"\"\n",
    "    result = {}\n",
    "    for key, value in lst:\n",
    "        if isinstance(value, list):\n",
    "            result[key] = create_dict(value)\n",
    "        else:\n",
    "            result[key] = value\n",
    "    return result\n",
    "\n",
    "lst = [('a', 1), ('b', [('c', 2), ('d', 3)])]\n",
    "print(create_dict(lst)) \n",
    "# Output: {'a': 1, 'b': {'c': 2, 'd': 3}}\n",
    "\n",
    "'''\n",
    "TESTING CELL\n",
    "dictdata = \n",
    " {'Model': [' 500', ' 900'], 'Task': ['71-00-00-200-802 ', '71-00-00-200-802']}\n",
    "{'a': 1, 'b': {'c': 2, 'd': 3}}\n",
    "type of testdata is  <class 'tuple'>\n",
    "type of testlist is  <class 'list'>\n",
    "jdata= {'Model': 'Task'}\n",
    "''';\n",
    "\n",
    "jdata = create_dict(testlist)\n",
    "print('jdata=',jdata)\n",
    "#jddata = testdata.json().dumps(testdata) # \n",
    "#jldata = testdata.json().dumps(testlist) # AttributeError: 'tuple' object has no attribute 'json'\n",
    "\n",
    "#print('type of jddata is ', jddata) # AttributeError: 'tuple' object has no attribute 'json'\n",
    "#print('type of ljdata is ', jldata) # AttributeError: 'tuple' object has no attribute 'json'\n",
    "\n",
    "'''\n",
    "myfile = 'short.json'\n",
    "pathfn=os.path.join(os.getcwd(), myfile)\n",
    "             \n",
    "with open(pathfn, mode='r', encoding='utf-8') as fpairs:\n",
    "    pairs = fpairs.readlines()\n",
    "    print(type(pairs))\n",
    "    print(dict(list(pairs.items())[:]))\n",
    "\n",
    "def convert_pairs_to_tuples(pairs):\n",
    "    tuplist = [(key,)+tuple(val) for dic in pairs for key,val in enumerate(pairs)]\n",
    "    return tuplist\n",
    "\n",
    "def convert_pairs_to_dict(tuplist):\n",
    "    truedict = {}\n",
    "    for key, value in pairs:\n",
    "        if key not in truedict:\n",
    "            truedict[key] = []\n",
    "        truedict[key].append(value)\n",
    "    return truedict\n",
    "\n",
    "tupls = convert_pairs_to_tuples(pairs)\n",
    "print(type(tupls))\n",
    "tups = jsonify(tupls)\n",
    "print(type(tups), datetime.datetime.now())\n",
    "print('Tups = ', tups)\n",
    "truedic = convert_pairs_to_dict(tupls)\n",
    "print(type(truedic))\n",
    "\n",
    "print('done pairs to dict ', datetime.datetime.now())\n",
    "\n",
    "#turn it into tuples first?\n",
    "\n",
    "testdata =  {\"Model\": \" 500\", \"Task\": \"71-00-00-200-802 \"}, \\\n",
    "            { \"Model\": \" 900\",\"Task\": \" 71-00-00-200-802\" }\n",
    "testlist=[  { \"Model\": \" 500\", \"Task\": \"71-00-00-200-802 \" }, \\\n",
    "            { \"Model\": \" 900\",\"Task\":\"71-00-00-200-802\" }]\n",
    "''';\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3599fa2-05b9-4285-9699-08dc2f14c7f2",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47c3a9c-437a-4067-a532-a7765443fbe7",
   "metadata": {},
   "source": [
    "Lakshmi Holla  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f42fdbf-c7b7-409f-b435-28d64d1607e3",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c323fbe6-dc6a-4dbc-9569-74c9041ea88c",
   "metadata": {},
   "source": [
    "Malika Singla  \n",
    "Ayushi Jain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffa5fb5-70ab-4f23-aee6-09cb260c1475",
   "metadata": {},
   "source": [
    "## Changelog\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9348598-d30b-4359-b163-8177b50bcb3a",
   "metadata": {},
   "source": [
    "| Date (YYYY-MM-DD) | Version | Changed By        | Change Description                 |\n",
    "| ----------------- | ------- | ----------------- | ---------------------------------- |\n",
    "| 2022-01-03        | 0.1     | Lakshmi Holla  | Created Initial Version\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f233ece-5867-4880-a325-d198f567a5b0",
   "metadata": {},
   "source": [
    "Copyright Â© 2022 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork21426264-2021-01-01&cm_mmc=Email_Newsletter-_-Developer_Ed%2BTech-_-WW_WW-_-SkillsNetwork-Courses-IBM-DA0321EN-SkillsNetwork-21426264&cm_mmca1=000026UJ&cm_mmca2=10006555&cm_mmca3=M12345678&cvosrc=email.Newsletter.M12345678&cvo_campaign=000026UJ).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
